{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/andres/thesis_project/keras_intel/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('Cart-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('SpaceInvaders-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unwrapped.get_action_meanings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/andres/thesis_project/keras2/lib/python3.6/site-packages/keras/engine/saving.py:269: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('/media/andres/Baymax/predictor.h5')\n",
    "encoder = load_model('/media/andres/Baymax/encoder100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DQNAgent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fe374c089d5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstate_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#377\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maction_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'DQNAgent' is not defined"
     ]
    }
   ],
   "source": [
    "env = gym.make('SpaceInvaders-v4')\n",
    "state_size = env.observation_space.shape[0] #377\n",
    "action_size = env.action_space.n\n",
    "agent = DQNAgent(state_size, action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from skimage import io, color\n",
    "from skimage.transform import rescale\n",
    "from skimage.draw import rectangle\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import closing, square\n",
    "import h5py\n",
    "\n",
    "def load_transform(image_path):\n",
    "    img = io.imread(image_path)\n",
    "    img = img[25:195,0:160]\n",
    "    img_gray = color.rgb2gray(img)\n",
    "    \n",
    "    thresh = threshold_otsu(img_gray)\n",
    "    bw = closing(img_gray > thresh, square(3))\n",
    "    cleared = bw\n",
    "    label_image = label(cleared\n",
    "\n",
    "    image_rescaled = rescale(cleared, 1.0 / 3.0, anti_aliasing=False)\n",
    "    #print(image_rescaled.shape)\n",
    "    image_reshaped = image_rescaled.reshape(3021)\n",
    "    image_reshaped[image_reshaped!=0] = 1\n",
    "    return image_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/thesis/keras/lib/python3.6/site-packages/skimage/transform/_warps.py:24: UserWarning: The default multichannel argument (None) is deprecated.  Please specify either True or False explicitly.  multichannel will default to False starting with release 0.16.\n",
      "  warn('The default multichannel argument (None) is deprecated.  Please '\n",
      "/home/andres/thesis/keras/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "state_transformed = load_transform(state)\n",
    "encoded = encoder.predict(np.expand_dims(state_transformed, axis=0))\n",
    "prediction = model.predict(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3021,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "actions = ['NOOP', 'FIRE', 'UP', 'RIGHT', 'LEFT', 'DOWN', 'UPRIGHT', 'UPLEFT', 'DOWNRIGHT', 'DOWNLEFT', 'UPFIRE', 'RIGHTFIRE', 'LEFTFIRE', 'DOWNFIRE', 'UPRIGHTFIRE', 'UPLEFTFIRE', 'DOWNRIGHTFIRE', 'DOWNLEFTFIRE']\n",
    "env_actions  = ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "\n",
    "from skimage import io, color\n",
    "from skimage.transform import rescale, resize\n",
    "import numpy as np\n",
    "\n",
    "from skimage.draw import rectangle\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import closing, square\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "\n",
    "model = load_model('/home/andres/Desktop/classifier_space_invaders.h5')\n",
    "\n",
    "def load_transform(img):\n",
    "    img = img[25:195,10:150]\n",
    "    img = resize(img, (60, 52), anti_aliasing=False)\n",
    "    img = color.rgb2gray(img)\n",
    "    img[img>=np.mean(img)] = 1\n",
    "    img[img<np.mean(img)] = 0\n",
    "    if np.mean(img) > 0.5:\n",
    "        img = 1-img\n",
    "    img = img.reshape(1, 60, 52, 1)\n",
    "    return img\n",
    "\n",
    "def get_action(state):\n",
    "    prediction = model.predict(load_transform(state))[0]\n",
    "    prediction_index = prediction.argmax()\n",
    "    try: \n",
    "        return env_actions.index(actions[prediction_index])\n",
    "    except:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_actions.index('FIRE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/andres/thesis_project/keras_intel/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guided Exploration Rate: 0.0, Goal: 10, Frames: 107\n",
      "Guided Exploration Rate: 0.0, Goal: 10, Frames: 104\n",
      "Guided Exploration Rate: 0.0, Goal: 10, Frames: 155\n",
      "Guided Exploration Rate: 0.0, Goal: 10, Frames: 168\n",
      "Guided Exploration Rate: 0.0, Goal: 10, Frames: 66\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "\n",
    "from skimage import io, color\n",
    "from skimage.transform import rescale, resize\n",
    "from skimage.draw import rectangle\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import closing, square\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "\n",
    "factors = {\n",
    "    'names': ['guided_exploration', 'reward_goal'],\n",
    "    'guided_exploration': [0.0],\n",
    "    'reward_goal': [1000]\n",
    "}\n",
    "\n",
    "def generate_experiments(factors, repetitions):\n",
    "    randomized = []\n",
    "    for factor_name in factors['names']:\n",
    "        randomized.append(factors[factor_name])\n",
    "    experiments_permutations = list(itertools.product(*randomized))*repetitions\n",
    "    return random.sample(experiments_permutations, len(experiments_permutations))\n",
    "\n",
    "actions = ['NOOP', 'FIRE', 'UP', 'RIGHT', 'LEFT', 'DOWN', 'UPRIGHT', 'UPLEFT', 'DOWNRIGHT', 'DOWNLEFT', 'UPFIRE', 'RIGHTFIRE', 'LEFTFIRE', 'DOWNFIRE', 'UPRIGHTFIRE', 'UPLEFTFIRE', 'DOWNRIGHTFIRE', 'DOWNLEFTFIRE']\n",
    "env_actions  = ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n",
    "\n",
    "model = load_model('/home/andres/Desktop/classifier_space_invaders.h5')\n",
    "\n",
    "def load_transform(img):\n",
    "    img = img[25:195,10:150]\n",
    "    img = resize(img, (60, 52), anti_aliasing=False)\n",
    "    img = color.rgb2gray(img)\n",
    "    img[img>=np.mean(img)] = 1\n",
    "    img[img<np.mean(img)] = 0\n",
    "    if np.mean(img) > 0.5:\n",
    "        img = 1-img\n",
    "    img = img.reshape(1, 60, 52, 1)\n",
    "    return img\n",
    "\n",
    "def get_action(state):\n",
    "    prediction = model.predict(state)[0]\n",
    "    prediction_index = prediction.argmax()\n",
    "    try: \n",
    "        return env_actions.index(actions[prediction_index])\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, guided_exploration_rate):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=1024*8)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0 # exploration rate\n",
    "        self.guided_exploration_rate = 0.0\n",
    "        self.epsilon_min = 0.1\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.05\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(16, (8, 8), activation='relu', padding='same', input_shape=(60, 52, 1))) #nb_filter, nb_row, nb_col\n",
    "        model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "        model.add(Conv2D(8, (8, 8), activation='relu', padding='same'))\n",
    "        model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "        model.add(Conv2D(4, (8, 8), activation='relu', padding='same'))\n",
    "        model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(self.action_size, activation='softmax'))\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            if np.random.rand() <= self.guided_exploration_rate:\n",
    "                return get_action(state)\n",
    "            else:\n",
    "                return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma *\n",
    "                          np.amax(self.model.predict(next_state)[0]))\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, batch_size=64, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)\n",
    "\n",
    "\n",
    "experiments = generate_experiments(factors, 1)\n",
    "\n",
    "# set constants (does not change between experiments):\n",
    "env = gym.make('SpaceInvaders-v4')\n",
    "state_size = 3120\n",
    "action_size = env.action_space.n\n",
    "batch_size = 256\n",
    "\n",
    "for experiment in experiments:\n",
    "    agent = DQNAgent(state_size, action_size, experiment[0])\n",
    "    goal = experiment[1]\n",
    "    goal_completed = False\n",
    "    num_frames = 0\n",
    "\n",
    "    while not goal_completed:\n",
    "        state = env.reset()\n",
    "        actual_reward = 0\n",
    "        state = load_transform(state)\n",
    "        while True:\n",
    "            num_frames = num_frames + 1\n",
    "            if np.random.rand() < 0.25:\n",
    "                action = 0\n",
    "                missed_frame = True\n",
    "            else:\n",
    "                action = agent.act(state)\n",
    "                missed_frame = False\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            actual_reward += reward\n",
    "            reward = reward if not done else -10\n",
    "            next_state = load_transform(next_state)\n",
    "            if not missed_frame:\n",
    "                agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "            if actual_reward >= goal:\n",
    "                goal_completed = True\n",
    "                break\n",
    "            if len(agent.memory) > batch_size:\n",
    "                agent.replay(batch_size)\n",
    "    print(\"Guided Exploration Rate: {}, Goal: {}, Frames: {}\".format(experiment[0], experiment[1], num_frames))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = generate_experiments(factors, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/thesis_project/keras_intel/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guided Exploration Rate: 0.75, Goal: 10, Frames: 153\n"
     ]
    }
   ],
   "source": [
    "# set constants (does not change between experiments):\n",
    "env = gym.make('SpaceInvaders-v4')\n",
    "state_size = 3120\n",
    "action_size = env.action_space.n\n",
    "batch_size = 256\n",
    "\n",
    "for experiment in experiments:\n",
    "    agent = DQNAgent(state_size, action_size, experiment[0])\n",
    "    goal = experiment[1]\n",
    "    goal_completed = False\n",
    "    num_frames = 0\n",
    "\n",
    "    while not goal_completed:\n",
    "        state = env.reset()\n",
    "        actual_reward = 0\n",
    "        state = load_transform(state)\n",
    "        while True:\n",
    "            num_frames = num_frames + 1\n",
    "            if np.random.rand() < 0.25:\n",
    "                action = 0\n",
    "                missed_frame = True\n",
    "            else:\n",
    "                action = agent.act(state)\n",
    "                missed_frame = False\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            actual_reward += reward\n",
    "            reward = reward if not done else -10\n",
    "            next_state = load_transform(next_state)\n",
    "            if not missed_frame:\n",
    "                agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "            if actual_reward >= goal:\n",
    "                goal_completed = True\n",
    "                break\n",
    "            if len(agent.memory) > batch_size:\n",
    "                agent.replay(batch_size)\n",
    "    print(\"Guided Exploration Rate: {}, Goal: {}, Frames: {}\".format(experiment[0], experiment[1], num_frames))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('/home/andres/Desktop/classifier_space_invaders.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('/home/andres/Desktop/classifier_space_invaders.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Closed HDF5 file>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_11\", \"layers\": [{\"class_name\": \"Conv2D\", \"config\": {\"name\": \"conv2d_1\", \"trainable\": true, \"batch_input_shape\": [null, 60, 52, 1], \"dtype\": \"float32\", \"filters\": 16, \"kernel_size\": [8, 8], \"strides\": [1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"MaxPooling2D\", \"config\": {\"name\": \"max_pooling2d_1\", \"trainable\": true, \"pool_size\": [2, 2], \"padding\": \"same\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Conv2D\", \"config\": {\"name\": \"conv2d_2\", \"trainable\": true, \"filters\": 8, \"kernel_size\": [8, 8], \"strides\": [1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"MaxPooling2D\", \"config\": {\"name\": \"max_pooling2d_2\", \"trainable\": true, \"pool_size\": [2, 2], \"padding\": \"same\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Conv2D\", \"config\": {\"name\": \"conv2d_3\", \"trainable\": true, \"filters\": 4, \"kernel_size\": [8, 8], \"strides\": [1, 1], \"padding\": \"same\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"MaxPooling2D\", \"config\": {\"name\": \"max_pooling2d_3\", \"trainable\": true, \"pool_size\": [2, 2], \"padding\": \"same\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Flatten\", \"config\": {\"name\": \"flatten_1\", \"trainable\": true, \"data_format\": \"channels_last\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"units\": 18, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.2.4\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('/home/andres/Desktop/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_intel",
   "language": "python",
   "name": "keras_intel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
